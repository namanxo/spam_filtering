{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzRo0Pw2XA1R",
        "outputId": "5ce5cd43-c2ff-4f31-9bf2-1090fc605cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.23 in /usr/local/lib/python3.10/dist-packages (0.1.23)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (3.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (2.2.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (2.4.1+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (4.66.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.23) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.23) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.23) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.23) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy==0.1.23) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy==0.1.23) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy==0.1.23) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.23) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.23) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.23) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.23) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.23) (2024.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy==0.1.23) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy==0.1.23) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy==0.1.23) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pgmpy==0.1.23"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator"
      ],
      "metadata": {
        "id": "942kRjnfipph"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and clean the data\n",
        "data = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
        "cleaned_data = data[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'message'})\n",
        "cleaned_data['label'] = cleaned_data['label'].map({'ham': 0, 'spam': 1})"
      ],
      "metadata": {
        "id": "8Y7voDCXinYY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cleaned_data['message'], cleaned_data['label'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "8ka_g8HdifRj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Vectorize text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "u3mDTwigicEj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Convert TF-IDF features to binary (presence/absence of words)\n",
        "X_train_binary = (X_train_tfidf > 0).astype(int).toarray()\n",
        "X_test_binary = (X_test_tfidf > 0).astype(int).toarray()"
      ],
      "metadata": {
        "id": "qb2UCctDiBrI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create a Bayesian Network model\n",
        "nodes = [f'word_{i}' for i in range(X_train_binary.shape[1])]\n",
        "nodes.insert(0, 'label')  # Add 'label' node"
      ],
      "metadata": {
        "id": "UOKXQtxyh-ZU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define edges where the label influences all word nodes\n",
        "edges = [('label', f'word_{i}') for i in range(1000)]\n",
        "model = BayesianNetwork(edges)"
      ],
      "metadata": {
        "id": "l684JI7Bh8KY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Prepare the training data as a DataFrame\n",
        "train_data_df = pd.DataFrame(X_train_binary, columns=nodes[1:])\n",
        "train_data_df['label'] = y_train.values"
      ],
      "metadata": {
        "id": "py69eifBh62c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using Maximum Likelihood Estimation\n",
        "model.fit(train_data_df, estimator=MaximumLikelihoodEstimator)"
      ],
      "metadata": {
        "id": "AeuHss5wh5hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Make predictions on the test data\n",
        "test_data_df = pd.DataFrame(X_test_binary, columns=nodes[1:])\n",
        "y_pred = model.predict(test_data_df)['label']"
      ],
      "metadata": {
        "id": "5wwR3mz7h3Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Evaluate the model\n",
        "report = classification_report(y_test, y_pred, target_names=['Ham', 'Spam'])\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "gXO8lGRqh0o8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}